{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation \n",
    "#### Anaconda 3-4.2.0 (or higher)\n",
    "#### Create virtual environment >> conda create -n yourenvname\n",
    "#### Activate virtual environment >>  conda activate yourenvname\n",
    "#### Install torchvision (Installs pytorch too) >> conda install -c pytorch torchvision\n",
    "#### Open Jupyter notebook >> jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2 as cv\n",
    "# from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Transformation\n",
    "#### Convert the Numpy arrays to PyTorch tensors and normalize input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset\n",
    "#### This is a built-in demo. Creating your own custom dataloader is discussed later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.label = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.label.iloc[idx, 0])\n",
    "#         print(img_name)\n",
    "        image = cv.equalizeHist(cv.imread(img_name, cv.IMREAD_GRAYSCALE))/255.0\n",
    "        labels = self.label.iloc[idx, 1]\n",
    "        labels = np.array([labels])\n",
    "        labels = labels.astype('float').reshape(-1, 1)\n",
    "        sample = {'image': image, 'label': labels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = customDataset(csv_file='labels2.csv',\n",
    "                                    root_dir='/home/dhull/vision/ass4/')\n",
    "imgs = []\n",
    "lbls = []\n",
    "\n",
    "for i in range(len(custom_dataset)):\n",
    "    sample = custom_dataset[i]\n",
    "    imgs.append([sample['image']])\n",
    "    lbls.append(sample['label'][0][0])\n",
    "imgs = np.asarray(imgs).astype(float)\n",
    "lbls = np.asarray(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 7)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(1296, 500)  \n",
    "        self.fc2 = nn.Linear(500, 100)\n",
    "        self.fc3 = nn.Linear(100, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original for white:\n",
    "Net(  \n",
    "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))  \n",
    "  (conv2): Conv2d(6, 16, kernel_size=(7, 7), stride=(1, 1))  \n",
    "  (fc1): Linear(in_features=1296, out_features=500, bias=True)  \n",
    "  (fc2): Linear(in_features=500, out_features=100, bias=True)  \n",
    "  (fc3): Linear(in_features=100, out_features=4, bias=True)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1296, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.318\n",
      "[1,   200] loss: 1.295\n",
      "[1,   300] loss: 1.339\n",
      "[1,   400] loss: 1.309\n",
      "[1,   500] loss: 1.193\n",
      "[1,   600] loss: 1.254\n",
      "[1,   700] loss: 1.040\n",
      "[1,   800] loss: 0.950\n",
      "[1,   900] loss: 0.783\n",
      "[1,  1000] loss: 0.652\n",
      "[1,  1100] loss: 0.523\n",
      "[1,  1200] loss: 0.397\n",
      "[1,  1300] loss: 0.358\n",
      "[1,  1400] loss: 0.256\n",
      "[1,  1500] loss: 0.109\n",
      "[1,  1600] loss: 0.192\n",
      "[1,  1700] loss: 0.342\n",
      "[1,  1800] loss: 0.068\n",
      "[1,  1900] loss: 0.134\n",
      "[1,  2000] loss: 0.095\n",
      "[1,  2100] loss: 0.090\n",
      "[1,  2200] loss: 0.038\n",
      "[1,  2300] loss: 0.098\n",
      "[1,  2400] loss: 0.049\n",
      "[1,  2500] loss: 0.031\n",
      "[1,  2600] loss: 0.171\n",
      "[1,  2700] loss: 0.108\n",
      "[1,  2800] loss: 0.119\n",
      "[1,  2900] loss: 0.025\n",
      "[1,  3000] loss: 0.128\n",
      "[1,  3100] loss: 0.031\n",
      "[1,  3200] loss: 0.031\n",
      "[1,  3300] loss: 0.003\n",
      "[2,   100] loss: 0.003\n",
      "[2,   200] loss: 0.001\n",
      "[2,   300] loss: 0.061\n",
      "[2,   400] loss: 0.013\n",
      "[2,   500] loss: 0.019\n",
      "[2,   600] loss: 0.018\n",
      "[2,   700] loss: 0.004\n",
      "[2,   800] loss: 0.117\n",
      "[2,   900] loss: 0.056\n",
      "[2,  1000] loss: 0.040\n",
      "[2,  1100] loss: 0.006\n",
      "[2,  1200] loss: 0.015\n",
      "[2,  1300] loss: 0.032\n",
      "[2,  1400] loss: 0.005\n",
      "[2,  1500] loss: 0.002\n",
      "[2,  1600] loss: 0.001\n",
      "[2,  1700] loss: 0.030\n",
      "[2,  1800] loss: 0.001\n",
      "[2,  1900] loss: 0.011\n",
      "[2,  2000] loss: 0.001\n",
      "[2,  2100] loss: 0.001\n",
      "[2,  2200] loss: 0.000\n",
      "[2,  2300] loss: 0.008\n",
      "[2,  2400] loss: 0.000\n",
      "[2,  2500] loss: 0.002\n",
      "[2,  2600] loss: 0.004\n",
      "[2,  2700] loss: 0.000\n",
      "[2,  2800] loss: 0.002\n",
      "[2,  2900] loss: 0.002\n",
      "[2,  3000] loss: 0.001\n",
      "[2,  3100] loss: 0.000\n",
      "[2,  3200] loss: 0.001\n",
      "[2,  3300] loss: 0.000\n",
      "[3,   100] loss: 0.000\n",
      "[3,   200] loss: 0.000\n",
      "[3,   300] loss: 0.002\n",
      "[3,   400] loss: 0.002\n",
      "[3,   500] loss: 0.002\n",
      "[3,   600] loss: 0.002\n",
      "[3,   700] loss: 0.000\n",
      "[3,   800] loss: 0.001\n",
      "[3,   900] loss: 0.000\n",
      "[3,  1000] loss: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cb1f197eaf65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhull/.conda/envs/ocr/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhull/.conda/envs/ocr/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mini_batch = 100\n",
    "loss_values = []\n",
    "test_values = []\n",
    "train_size = int(0.8*len(imgs))\n",
    "test_size = len(imgs) - train_size\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i in range(train_size):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = torch.from_numpy(np.asarray([imgs[i]])).float()\n",
    "        label = torch.from_numpy(np.asarray([lbls[i]])).long()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % mini_batch == mini_batch-1:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / mini_batch))\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            test_loss = 0.0\n",
    "            for j in range(train_size,len(imgs)):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = torch.from_numpy(np.asarray([imgs[j]])).float()\n",
    "                labels = torch.from_numpy(np.asarray([lbls[j]])).long()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "            test_values.append(test_loss/test_size)\n",
    "            loss_values.append(running_loss/mini_batch)\n",
    "            running_loss = 0.0\n",
    "        \n",
    "plt.plot(loss_values)\n",
    "plt.plot(test_values)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4b7acdb690>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd8XNWZ//HPM0Uz6l2yrOJu2cYVhG3AdEhsklAWAnY2jRDYBEjIkk1Ifslms2GzWZJNYXchLLCQhBAILeCAQzVgMNjYxr2r2Fa1em9Tzu+PO5IlWbLG9lgzkp7366WXNPcejR5r4DtH55x7rhhjUEopNbbYwl2AUkqp0NNwV0qpMUjDXSmlxiANd6WUGoM03JVSagzScFdKqTFIw10ppcagYcNdRB4TkWoR2TVMu3NFxCsiN4SuPKWUUqcimJ7774DlJ2ogInbgPuD1ENSklFLqNDmGa2CMWScik4dp9g3geeDcYH9wWlqamTx5uKdVSinV15YtW2qNMenDtRs23IcjItnAdcClDBPuInIbcBtAXl4emzdvPt0fr5RS44qIHA6mXSgmVH8D3GOM8Q/X0BjzsDGmwBhTkJ4+7BuPUkqpU3TaPXegAHhaRADSgKtExGuMeTEEz62UUuoUnHa4G2Om9HwtIr8DXtZgV0qp8Bo23EXkKeASIE1EyoB/AZwAxpiHzmh1SimlTkkwq2VWBftkxpgvn1Y1SimlQkKvUFVKqTFIw10ppcagMRfuXV4fz2wqpbnTE+5SlFIqbMZcuP/P2kK++/wObv39Zjo9vnCXo5RSYTH6wr2pDHa9AEVroWIr1JdAVysAhdUtPPRuEWdNTGBjST3fenobPr/eAFwpNf6E4iKmEdVd8gFRL97a/6DNifn0r/h/m2YQE+Xg919ZzEvbKrj35T386KVd/Nu1cwlcZKWUUuPCqAv3lzvm81DXfVwxOYpvXpCO29MMO59BVn+Dszxf4O+u+S5pcS5uWTaFmpYuHnq3iIx4N3ddMSPcpSul1IgZdeF+3dJ8mvwu7n15D2s74nn0S5cTPeUzbP3NDfyL8wn87XlgvgMi3LM8n5qWLn795gEKJidzwfS0cJevlFIjYtSNuYsIN18whcdvXkx5YwfXPrCeu57byx3d36Bp5g3Y3vkpvPHPYAwiwk+vm0uU3cY7+6vDXbpSSo2YURfuPS6emc5fbr+AOJeD9wtr+erFM0hc+Qiceyt88N/wwm3g6cTttLMgN5GPDjWEu2SllBoxo25Ypq/pGXG8eMcFrNlZxd+dnQ02G1z1C4ifAGvvhYZDsPJPFExO4ZF1xbR3e4mJGtX/ZKWUCsqo7bn3SIqJ4nNL8nA77dYBEbjon+Czv4eqnfDoZVyaVIvXb9h2pDG8xSql1AgZ9eE+pLOuhZvXgLebc9fexGzbETbp0IxSapwYu+EOkH023LoWETv3xK5h06H6cFeklFIjYmyHO0BiNpzzRS70rKfiyEG8vmHvBqiUUqPe2A93gMW3YcNwo/9V9lQ29zvV6fHx1d9vYkNxXZiKU0qp0Bsf4Z6UR+eMT7HK/hZbC8v7nXppWzlv7q1m7T5dB6+UGjvGR7gD0Rd9k0RpJ2rX073H/H7DI++VAFBa3x6u0pRSKuTGTbiTu5jD7jmcX/ssxm9tBfzugRoKq1txO22UNmi4K6XGjvET7kDprJuZRCVHN78EwMPripmQ4ObahdmU1neEuTqllAqdYcNdRB4TkWoR2TXE+b8XkR0islNEPhCRBaEvMzQmLP0s5SYV2fgQu8qb+LC4jq8sm8yUtFiaOjx69yal1JgRTM/9d8DyE5wvAS42xswD7gUeDkFdZ8S0zCSesa0gs24jr7zxOnEuBysX55GbEgPouLtSauwYNtyNMeuAIa/+McZ8YIzpufRzA5ATotpCTkQ4lHcD7biZVvQEK8/NJcHtJDe5J9x1aEYpNTaEesz9FuBvIX7OkJo7bRLPei/kM7b13LIoDoDclGgAynRSVSk1RoQs3EXkUqxwv+cEbW4Tkc0isrmmpiZUP/qkFExO5nHfclziJevAkwAkRjuJdzl0WEYpNWaEJNxFZD7wKHCNMWbISz2NMQ8bYwqMMQXp6emh+NEnbX5OEldfeiEdk6+ETY+CpxMRISclhtIGHZZRSo0Npx3uIpIHvAB8wRhz4PRLOrPsNuHuT+QTfdE3oL0Wdj0HQG5ytPbclVJjRjBLIZ8CPgTyRaRMRG4Rka+JyNcCTX4EpAIPisg2Edl8BusNnSkXQeZc+PBBMIbclBjKGjowxoS7MqWUOm3D3pbIGLNqmPNfBb4asopGiggs/Tq8dAeUrCM3OY8Oj4/a1m7S413hrk4ppU7LuLpC9Thzb4DYdNjw4LG17rpiRik1BozvcHe6oeAWOPAqU21VgF7IpJQaG8Z3uAMUfAWA7Mo3ACjTFTNKqTFAwz0+E2JSiWotJy0uSnvuSqkxQcMdIDEHmsrISY7RMXel1Jig4Q6QmAtNZeSmxOj+MkqpMUHDHSAh2wr35GgqGjvw+XWtu1JqdNNwB2tYpquZqfE+vH5DZZP23pVSo5uGO1jhDkx1NgK69a9SavTTcAdrzB3IsdUCeiGTUmr003CH3p57iq8aESjT5ZBKqVFOwx0gLhNsThwtFWQluHXrX6XUqKfhDmCzQcJEa617SoxeyKSUGvU03HsELmTK1QuZlFJjgIZ7j55wT4nmaHMXnR5fuCtSSqlTpuHeIzEHmsvJTbL2ci9v1HF3pdTopeHeIzEHjI+p7lZAt/5VSo1uGu49Amvdc+3W/b11xYxSajTTcO/Rs9bdW0NMlJ19lc1hLkgppU6dhnuPhGwAbM1lLJuextp91XqzbKXUqKXh3sOdAK5EaCrjyjmZVDZ1srtCe+9KqdFp2HAXkcdEpFpEdg1xXkTkv0SkUER2iMjZoS9zhASWQ142KwMReHPv0XBXpJRSpySYnvvvgOUnOL8CmBH4uA347emXFSaJOdBUSmqci3Pyknljj4a7Ump0GjbcjTHrgPoTNLkG+IOxbACSRCQrVAWOqEDPHeCKOZnsrmimQte7K6VGoVCMuWcDpX0elwWOHUdEbhORzSKyuaamJgQ/OsQSc6CjAbrbuGJ2JgBv6dCMUmoUGtEJVWPMw8aYAmNMQXp6+kj+6OAE1rrTVM609FimpMXyxt7q8NaklFKnIBThXg7k9nmcEzg2+gTWutNUiohw5ZxMPiyqpaXTE966lFLqJIUi3FcDXwysmlkKNBljKkPwvCMvMTCa1DPuPjsTj8/w3sHaMBallFInzzFcAxF5CrgESBORMuBfACeAMeYhYA1wFVAItAM3n6liz7j4LBBbb7ifnZdEcoyTN/Yc5ap5o3OOWCk1Pg0b7saYVcOcN8AdIasonOxOK+AD4e6w27h0VgZv7a3G6/PjsOs1X0qp0UHTaqDAWvcen8hP5j+9P+PQ24+HsSillDo5Gu4D9VnrDnBp3dNcaf+Yzr2vh7EopZQ6ORruAyXmQHMF+P1QcwDX+v8EwLTpkkil1Ogx7Jj7uJOYC74uaKuGv94FzhhKomYQ3VkX7sqUUipo2nMfKLD1L2v/DY58AJ/8KW1Js0jyN+h6d6XUqKHhPlDPhUxbn4ApF8HCv8edPJEUWiisaghvbUopFSQN94F6wt3hhs/cDyIkZWRjE0NpWemJv1cppSKEjrkPFJ0Mky6AuddDylQAkjOswK+pPAKcE8bilFIqOBruA4nAzWv6HbLHTwCguaZssO9QSqmIo8MywYjLAKCjoSrMhSilVHA03IMRCHdHew3t3d4wF6OUUsPTcA+GMxqPM550aaSwujXc1Sil1LA03INkYtNJlyYOHtVwV0pFPg33IDkSJpAhjRzUnrtSahTQcA+SLT6TLEcLhdUt4S5FKaWGpeEerLhMUtGeu1JqdNBwD1ZcBjH+No7WN9LR7Qt3NUopdUIa7sGKtZZDptFEUY323pVSkU3DPVhxmQCko8shlVKRT8M9WIELmTJtTRzUSVWlVIQLKtxFZLmI7BeRQhH53iDn80TkbRHZKiI7ROSq0JcaZoGe+6z4Dl3rrpSKeMOGu4jYgQeAFcAcYJWIzBnQ7IfAM8aYRcBK4MFQFxp2sWmAMD2mXVfMKKUiXjA998VAoTGm2BjTDTwNXDOgjQESAl8nAhWhKzFC2J0Qk0qus4XDdW10evqsmClaC2VbwlebUkoNEEy4ZwN971JRFjjW14+Bz4tIGbAG+EZIqos0cRlk2JrwGyipbTt2fPU34Z2fha8upZQaIFQTqquA3xljcoCrgCdE5LjnFpHbRGSziGyuqakJ0Y8eQXEZJPqsW+31Ds2010NTKXQ2hrEwpZTqL5hwLwdy+zzOCRzr6xbgGQBjzIeAG0gb+ETGmIeNMQXGmIL09PRTqzic4jKJ7qrFJlB4NLBipmqH9blDw10pFTmCCfdNwAwRmSIiUVgTpqsHtDkCXA4gIrOxwn0Uds2HEZeBtFUzOTWGPZWBcK8MhLv23JVSEWTYcDfGeIE7gdeAvVirYnaLyE9E5OpAs28Dt4rIduAp4MvGGHOmig6buEzwdrJkopPtZY0YY/r33MfgP1kpNToFdQ9VY8warInSvsd+1OfrPcAFoS0tAgW2IDg3zctTO7qoau4kq6fn7veApwOiYsJYoFJKWfQK1ZMRuEp1blInADtLqqDuYO8FTjo0o5SKFBruJyMQ4pNdrThswtGDm8H4YcpF1nmdVFVKRQgN95MRCPeojlpmZcXjKd9uHe8Jd+25K6UihIb7yYhOBpsDWo+yICeJ+Ia9GHcSZM61znc2hbc+pZQK0HA/GTabNanaWs2C3CRmmGI6Us+C6CTrvA7LKKUihIb7yYpLh7ZqFkyMY5aUUu6aDu5AuOuwjFIqQmi4n6y4TGg9ynRbBW7xsMM3CdyJ1jntuSulIoSG+8mKs4Zl7Ed3AvB2cxbY7OBK0DF3pVTE0HA/WXGZ0FoNFdvwiIu3qhPo9vqtoRkdllFKRQgN95MVlwnGB8Xv0JqUT4dP2FfVbA3N6LCMUipCaLifrNjAbpY1e3FmLwBge2mjtWJGe+5KqQih4X6yerYaAGInnU1qbBTby5qsnruOuSulIoSG+8nqE+6SNZ8FuUnHeu46LKOUihAa7icrsHkYYoOMOSzISaKwppVuZ4IOyyilIoaG+8lyxYMjGtJmQlQM83MTMQaqutzgaQdvd7grVEopDfeTJgJp0yHvPAAW5FhXpx5ud1rnddxdKRUBgrpZhxrgS38FuwuAlNgo8lJiONjs4EKwhmbiRuH9YZVSY4r23E9FdHK/Oy4tyE1id13ggU6qKqUigIZ7CCzISaSkrWdYRsNdKRV+Gu4hsDA3iSZirQc65q6UigAa7iEwNzuRFomzHnQ0hLcYpZQiyHAXkeUisl9ECkXke0O0uVFE9ojIbhH5U2jLjGxup52szAnWAx2WUUpFgGFXy4iIHXgAuBIoAzaJyGpjzJ4+bWYA3wcuMMY0iEjGmSo4Up2Vl05HQxTu9kYk3MUopca9YHrui4FCY0yxMaYbeBq4ZkCbW4EHjDENAMaY6tCWGfkW5ibRZGJpbqobvrFSSp1hwYR7NlDa53FZ4FhfM4GZIrJeRDaIyPLBnkhEbhORzSKyuaam5tQqjlA94d7aMLb+XUqp0SlUE6oOYAZwCbAKeEREkgY2MsY8bIwpMMYUpKePrQt9pqXH0SaxdLXWh7sUpZQKKtzLgdw+j3MCx/oqA1YbYzzGmBLgAFbYjxt2m2DcujOkUioyBBPum4AZIjJFRKKAlcDqAW1exOq1IyJpWMM0xSGsc1Rwxafg9LbQ6fGFuxSl1Dg3bLgbY7zAncBrwF7gGWPMbhH5iYhcHWj2GlAnInuAt4HvGGPG3cxiXFIaibSxt7I53KUopca5oDYOM8asAdYMOPajPl8b4O7Ax7iVmppOfGE724/UsSgvOdzlKKXGMb1CNYTik6xJ4gOHB05JKKXUyNJwD6Voa4HQofLKMBeilBrvNNxDyW2Fe3NDDY3tekcmpVT4aLiHkjsRgERpY3uZ7g6plAofDfdQCgzLJEkb20t1vbtSKnw03EMpMCwzLd7HNg13pVQYabiHUqDnnp9ohbu1QlQppUaehnsoOWPA5mByrIf6tm4O17WHuyKl1Dil4R5KIuBOYqKrC4CtpXpXJqVUeGi4h1p0Eom2dmKi7Gw9ouPuSqnw0HAPNXcSts5GFuQkabgrpcJGwz3U3InQ0cjZk5LYW9lMR7fuEKmUGnka7qEWnQSdjSzKTcbrN+ws14uZlFIjT8M91NxJ0NnEwjxrWeTWIzqpqpQaeRruoRYYlkmLjSIvJUbH3ZVSYaHhHmrRSWB80N3KorwkPj7SoBczKaVGnIZ7qAW2IKCjkbPzkqlu6aKyqTO8NSmlxh0N91ALbEFAZxOLesfddWhGKTWyNNxDLbDtL52NzJqQgMth42OdVFVKjTAN91DrMywT5bAxLztRV8wopUZcUOEuIstFZL+IFIrI907Q7noRMSJSELoSR5neYRlrKGZRXhK7Kprp8urFTEqpkTNsuIuIHXgAWAHMAVaJyJxB2sUDdwEbQ13kqOI+NuYOsCgvmW6vn72VLWEsSik13gTTc18MFBpjio0x3cDTwDWDtLsXuA8Y30tDXAmAQIfVcz87LxnQi5mUUiMrmHDPBkr7PC4LHOslImcDucaYV0JY2+hks4E7oXdYZkKim6xENx/rihml1Ag67QlVEbEBvwK+HUTb20Rks4hsrqmpOd0fHbncSb09d4Dzp6Xx+u4qCqt1aEYpNTKCCfdyILfP45zAsR7xwFzgHRE5BCwFVg82qWqMedgYU2CMKUhPTz/1qiNddFLvmDvAPSvyiXU5uOvpbXR7/WEsTCk1XgQT7puAGSIyRUSigJXA6p6TxpgmY0yaMWayMWYysAG42hiz+YxUPBqkTIWyTeDpACAj3s19189nd0Uzv3xjf5iLU0qNB8OGuzHGC9wJvAbsBZ4xxuwWkZ+IyNVnusBRqeAW6KiHHX/uPXTlnExWLc7j4XXFfFhUF8bilFLjgYRrU6uCggKzefMY7dwbA/97Ifg8cPsG696qQHu3l0/91/t0eny8etdFJMY4w1yoUmq0EZEtxphhryXSK1TPBBFYejvU7IOitb2HY6Ic/OamhdS0dPHjv+4OY4FKqbFOw/1MmXs9xGbAhgf7HV6Qm8Tnl07ilR2VtHd7w1ScUmqs03A/UxwuWHwrFL4JNf0nUS+blUG3z89HJfWn9NRdXp9uRqaUOiEN9zPpnJvB7oINv+13ePGUFKIcNt4/WHtKT/vnTaVc/9sPqG4Z3xcDK6WGpuF+JsWlw/wbYfvT0H6sl+522imYlMz7hacW7jvKmjAGKho13JVSg9NwP9OWfh28HbDl8X6Hl81IY19VCzUtXSf9lPuqmgE42qzhrpQanIb7mZZ5Fky+EHY80+/wsulpAHxQdHK9d6/Pz4GjrQBUn8Ibg1JqfNBwHwmTzofaA9Dd3nvorImJJMU4ee8kx92La9t6tzCo1p67UmoIGu4jYcI8MH6o3tt7yG4Tzp+WyvrCWoa9kKxqJ7z6/8DvZ2+lNSQjosMySqmhabiPhAnzrM9V2/sdXjY9ncqmTopq2k78/TuegQ0PQHM5eytbcNqF/Mx4HZZRSg1Jw30kJE2ybuJRtbPf4Z5x9/XDrZqpLw58LmJvZTPTM+LJSY7maLOGu1JqcBruI0HE6r0PCPe81BjyUmKGH3fvCfe6QvZVNTN7QjwZCW4dc1dKDUnDfaRMmA9Hd4O//42yL5iexobiOry+IfZ59/uhvgSAzqqDHG3uYnZWAhnxLurauvEM9X1KqXFNw32kTJgHnvZjvfCAC2ek0drlZXvZELfha62y1skD7VUHAJidlUBmghvglNbJK6XGPg33kdI7qbqj3+HzpqYiAu8fHGKP9543A3cStoYiAGZlxZOZ4AJ0xYxSanAa7iMlfRbYnMeNuyfHRjEvO5H3C4e4p2ydFehMv5z49jImxDlIi3OREW/13HXFjFJqMBruI8URZQV85Y7jTi2dmsq20sbB769aX2y9KUy5GDs+lqVbF0JlBHruOqmqlBqMhvtIGmTFDMBZExPw+AxFNa3Hf099MSRPxpsyHYBzE6wNyFJjXdhtosshlVKD0nAfSVnzoa0aWo72O3zWxAQA9lQ0H/899cWQMpVDTARgttMavrHbhLS4KN32Vyk1KA33kdQ7qdq/9z4lLQ6308aeygHhbowV7qnT2NXgpNlEk2sqek9nJritnnvVLnj0CugYYsWNUmrc0XAfSZlzrc8DVszYbUL+hITje+6tR63lkylT2VvVwmGTRWJHae/pjHi3tVpm9wtQtgnKx+gNx5VSJy2ocBeR5SKyX0QKReR7g5y/W0T2iMgOEXlLRCaFvtQxIDoJkvIGHXefk5XA7oqm/puI9ayUSZnC3qoW6ly52OqLek9nJLisde6HP7QO9NmYTCk1vg0b7iJiBx4AVgBzgFUiMmdAs61AgTFmPvAc8PNQFzpmTJg/5KRqc6eX8saOYwd71rinTGNvZTPdiVOgqRS81iRqZryb1rZWTE+PvXrfma4+eGv/DTY/Fu4qlBq3gum5LwYKjTHFxphu4Gngmr4NjDFvG2N6NivfAOSEtswxZMJ8qCuE7v47Qc4ZbFK1vhhsDmodGdS0dBGVMd3aOrjhEACZCS7mSzHi67bu1VoTIT13nwc++B/Y+sdwV6LUuBVMuGcDpX0elwWODeUW4G+DnRCR20Rks4hsrqkZ4qKdsW7CPMBY+8z0MWtCPCL0n1StL4KkSew7avXmk/MCfzDVFQLWsMy5tkBvfc41ULPf2osm3Kp2Wlsm1BywJoWVUiMupBOqIvJ5oAD4xWDnjTEPG2MKjDEF6enpofzRo8cQ2xDERDmYkhZ7fM89ZWrvvjN5MwLfGxiLz4h3s9i2n5aEGTDpPOhutYZtwq30I+tzdwu0VIa3FqXGqWDCvRzI7fM4J3CsHxG5AvgBcLUxRq+sGUpiDriThpxU7e25G2PtBpk6jdd3VzEvO5Hk1AyITrF69EBmnJNzbAeoSFwI6bOt76uJgHH30g3Hvq7ZH746lBrHggn3TcAMEZkiIlHASmB13wYisgj4X6xgrw59mWNIz97upZuOG0KZMzGBsoYOmjo80FoN3a00uHPYXtbEp+ZnWY1Sp/f23FNb9xMvHRx0z4eMWdb5SFgxU/qRdVNwsO4dq5QaccOGuzHGC9wJvAbsBZ4xxuwWkZ+IyNWBZr8A4oBnRWSbiKwe4ukUwLwboHo3vPPv/Q6fNTERCEyqBlbKfNhgHfvUvJ5wn9Yb7rZAD3mbzIboZIjPClvP/Su/28Sv3zgAjaXQXA6zPg3uxMj4S0KpccgRTCNjzBpgzYBjP+rz9RUhrmtsO/tLUL4F1v3C2kxs3g2ANSwD1qTqebFWuL9U6mZ+TiK5KTHW96ZOg+1PWattDq/nqC2Tg53WGwDps8LSc2/t8vL2/mo2FNfxDylNxADkLYG0fGtSVSk14vQK1XAQgat+CXnnw0t3WEEPpMe7SI939fbcjdh5q9LFVT29doCUadbnuiI4/CFFMfOP7emeMTssK2b2VjZjDLR3+yjZ+hY4YyBzHqTnQ62OuSsVDhru4eKIgpuegLgMeOpz0GztGdM7qVpfRLM7Cy+OY0MyYPXcAQ6+Bu21HE1adGxP94zZ1hLExkMj+k/ZWdYEwMzMOOzlm/BnnwN2hxXubTXQXj+i9SilNNzDKzYNVj1tLWF8ahV0tzFnYgKF1S3464op9GayoO+QDBzruQcuEGrOWEx9W7e1F3zPipkRvlJ1V0UT6fEu7rksh+n+QxS5A3vopOVbn3VSVakRp+EebplnwfWPQuV2eOE25kyIw+Pz46stYmdHav8hGQBXHMRNsK5SjU3HlTkTgJrWLqunDHRW7ubBdwpp7vSMyD9hV3kTcycmcElcKQ7x80xVoOZ0qzadVFVq5Gm4R4L8FbD8Z7DvZS489N+k0ozT28phk3l8uMOxoZm8pWQmRgOBe6m6EyAxl5Ldm/j5q/v55xd3nfHSO7p9FFa3Mi87EXuZdfHSn6uy2F7aCIl54IgOalL11V2V/PadomHbKaWCo+EeKZZ8DRbfRtK2h/ih62kAJHVa/yGZHr3hfj7p8T2327PG3f3p+dhr9xPvcvDStgpe3Hrc9WYhtbeqGb+Bs7IToXQjvrRZ+F2JPLa+BGw2SJuOqdnPB0W1FFa3DPk8/722kF+9sZ/WLu8ZrTeUjG6toCKYhnukEIFP/gxmfILr5F0A8ucsGLxtqnXLPSadR2ZCz42yrRUzJZLHJFPOrz47j4JJyfzzi7sorW8f/HlCYFe5NZk6b2I8lG7CnreEGwtyeWVHJfurWig0ORwt3s7nHtnInX/aOuhz1Ld1s7uiGY/P8EFh7RmrNZS6vX6W3fc2j68vCXcpSg1Kwz2S2B1ww2NUuqfTZRycf87Zg7dbsAqW3wdZC0mNjQrcS9UK99eqk3CJh8sy2/j1TQsB+Mc/b8PrOzPLI3eVN5ESG0VW9yHoaoK8pXz5/Mn4jOGTv1nHi2VxTDA1XHtWIvuqWqjou6VxwAdFxwL93QOjY0O5neWNlDd28MDbRXR6fOEuR6njaLhHGlc8vs+/xMaL/0BuetLgbeIyYOnXQASbTUiPc1Hd3MX+qhb+Vp0CgL1mL7kpMdx77Vw2H27gwZMcz95f1UKXd/jQ2lXezFkTE5CezcJyl5CXGsPdV8zk80vzuGmFdX3b3Yus/9Te2X98eK8vrCPe5eCyWRm8s79mVAx3bCyxlnfWtnbx0rYzO/Sl1KnQcI9AOTk5XHTZp4Jun5ng4mhLF09sOMQRe2Ar/cAKlWsXZXPtwonc/9ZBPv/oRv7jb/tYs7Oy/01BBiiqaWXF/ev46Ssnvtq10+PjwNEW5gXG24lJg5SpAHzj8hn827XzyJ1p/fWQ6ztCdlI0a/cdv/XQ+sJabsyp44spuylv7KCopu24NpFmY3E90zPimJOVwMPrivH7I/8NSY0vGu5jQEaCm5LaVv7ycTlXzJ8KSZP6bUNw77Vz+fySPBrau3n0vWJlCmGfAAAR8ElEQVRuf/Jjlt23lld3Db4d76PvFeM38OTGIyecBD1wtAWv3zB3Yjwceh9yl1hzB32lTAWxI7UHuGxWBusLa/v9RXCkrp0j9W3c2fRLLt72T2RRxzv7I3vvOa/Pz5bDDSyZksJtF02lqKaNtyO8ZjX+aLiPARnxLkrrO2jr9vHF8yYFtiE4trY83u3kX6+ZyyvfvJBd//pJXrrjAmZkxPEff9uHZ8BYfE1LF89/XM5V8yYQE2Xn39cEnqer9bgbb+wMTKae273J2kc+sEdOP44oa3VPzX4unZVOh8fHRyXHrlhdX1RLgewnubUQ8Xv4fvyaiB9331PZTGuXlyVTU/nU/CwmJrr533XF4S5LqX403MeAnhUz83MSWZCbZIV77UHrdncDuJ12FuQm8Z1PzuJQXTvPbSnrd/4PHx7C4/Pz7U/k843LprN2XzU73n8Z/nMmvPnjfm13lTeTGO0kbff/QUI2zP7M4AWmzYTaA5w3NQ2Xw9ZvaOb9wlpujX4b40qA+Sv5lPcNjhQfoL07cpdE9rw5LZmSgtNu4yvLpvBRST3bShvDXJlSx2i4jwGZCdZa9y8snWQdSJ8Nfg88tAwev8rau+avd/XbluCK2Rksykvi/jcP9q72aO/28sSGw1wxO5Np6XF86fzJfCaxiJlvfgXj64IPH7BuIBKwu6KJFRl1SMk6WHwr2J2DF5ieD/XFRNt8nDcttXdS1e837D1YxOVmA7JgJVz2Q0SEW+UvbCiuOwO/qdDYUFzP5NSY3jfVlYvziHc7eER77yqCaLiPAVfMzuSbl8/g6oUTrQMzPwEFXzm2Hr7hEOx8zgr7t+4FTwciwnc+mU9Vcyd/3HAYgOe2lNHY7uEfLrImRV1lG/i1998p9afx2nl/ApsD1t4LWOu891W2sNL/inUV6tlfGrrAtHzwe6G+mEvzMyipbaOkto09lc18ovtNHMZj1ZuUi3/hF7jR/g5bdx5/p6rTUdbQzp1/+pja1tO7SZjfb9h0qJ7FU1J6j8W5HPz9kkn8bVclR+rO3DUFSp0MDfcxIDXOxd1XzsTlsFsHopPh07+GlU/CzWvg9g/gru3WmPh7/wkPngdFazl/WhoXzkjjwXeKaOrw8Oh7JSzKS+KcSclw+AN48rPYk3O5L+Pn/HCjne7Ft8Ou56F8CwerW4jzNTKv7jVYcBPEpAxdYM8eM7X7uTQ/A4C391Wz/mA1n7O/RXf2edZQEuC4+NuI2Ji+/+GQ/o7+Z20hL++o5Oevnt4+N/uPttDU4WHJlNR+x2++YDJ2m3DL7zfxYVHk/tWhxg8N9/EiNg2uewi+uBrEBk9cB39ayQ8L/NS3dXPz4x9xpL6dOxYnI6//EP5wLSRmI196mTuvWUZtaxdfK74AX3QqvP4jdpU1ssq+Fru/G5Z8/cQ/O61nA7ED5KXGMC09lrf3V9O06zXybDVELf3qsbaJORTl/h0rPG9SWhyaveCrmzt54eNykmKcPLuljB1lpz42vjEwXLRkav83s8wENw9/sYD2bh+rHtnAN57aSmXT0MtNlTrTNNzHm6kXw9c/gMt/BEc+IP8vK3gm7VG6Srfy4/iXuPz1K2HDgzD3evjyKxCfycLcJH5+/Xw2Vnj4Wds1cPh9vHv+yhcdb2CmXnrs/q1DiYq1NhE7/D50t3FpfgYbi+s5p+YFWh3JMPvqfs3jr/guBqHzzZ8et0LnVDy2/hBev58/3rKE1FgXP169+5QvlProUD3ZSdHkJB+/58+l+Rm89e2LuevyGby2u4rLf/nuGd/bR6mhaLiPR043XPhta6jmwrsp6PyQV1w/4MuePyPTL4fbN8B1v7WuhA248dxcXv3WRRzIvZ5i/wSuK/kJmdKALL09uJ859zoofgd+M58v+P5Cnv8Il/AxNdNvtJZL9pE9aTqro65iRsVLlDx0I0+t28EfNxw+pX1nWjo9PLnhMCvmZTE3O5HvLs/n4yONvLSt4qSfyxjDRyX1LJky9BCU22nnH6+cyVt3X8zc7ET+6dnt/ZZ+DsXvNzy7uZTnB6xeOhldXh+H6yL/AjA1MiRcl3oXFBSYzZs3h+VnqwFaq+nc+mdc05YhExedsKkxhvdWP8ZFW++mITqP5O9st3Z/DMaRjbDu51D4Jj4jCND+9S3ETZh2XNNfvbYHz7r7udvxLEdJ5q7uO9hi8vmXz8zh5gumBP1Pe/jdQp5/9Q1+f95RJrQdwD/nGq5fl0lFi5e1376EWFdQtxEGoLC6lSt+9S73XT+PmxakwkcPQ2cTuOLBlWDdEDxrIaTNABGaOjxc98B6mjo8vHTnBYP29gFKatv43vM7erc0+M4n87nj0ulB1wXW1cJffvwjPiqp54HPnc2KwbaKVmOCiGwxxhQM2y6YcBeR5cD9gB141BjzHwPOu4A/AOcAdcBNxphDJ3pODfdRzBh8f7sHpl6KfdaKk//+si3seubHVJLOlXc/NsSPMDR3epHyLcT+9TZszaW8E381b9SlcsW587isYJ413NPRAO111kdnU2AYx/pv2ttSTeXGF8ilChCIy4TWKrpis/mPxstIvOArfP0TC9hT0cz20kb2VbVgtwlxLgdxLgcJ0U6unJPJxCRrz/wnNx7mB3/ZxYc32ch697vQeARsTmvZaV8pUyH/KshfQZH7LK596CNykmN4/uvnERN17M3E6/Pz2PoSfvn6AaIcNn5w1Ww2FNfx4rYK/vGKmdx1xYygfp3dXj9f++MW3t5fzZS0WErr23nkiwVckp8x/DerUSdk4S4iduAAcCVQBmwCVhlj9vRpczsw3xjzNRFZCVxnjLnpRM+r4a6C1tkMf/suZvvTCMH/pekXB+9555B13o3MvOgma++bg6/D+vvhyAe0mGj2mzwOm3RKTQaNzizqJZGK7hiqfbE0mlh8djfXnD2Zr186gwfWbOKCol/zGfO2tcz0M/8Fk84Hb6dVY0eDNa+wbw2UrLNC3xlDQ/J8/lgxAclbyq03fJpNNVGsPVDHG3urKK3v4Mo5mfz0qslkeCvxYeeedzt5bmsl37xsOv945Uxk4JYOffj8hrue3srLOyr56XVz+fT8iXzukQ0U1bTy+5sXs2SqtarHGMO20kZ2lDVxSX46k1JjT/tlUeERynA/D/ixMeaTgcffBzDG/KxPm9cCbT4UEQdQBaSbEzy5hrs6aT4P3c3V3PfcuxSVFHPjvCTS0rPodiXTHZWMz5VASpyb1NgokmNd3PjIJmyOKNZ8c9lxAVm//z32rPktuf5KMnxVuNsrT/jG4THWMlObGOzLvgUX32PNXQylsxmK34ZD66F0A/6qXdiMr/e5qkmmzZ1JRqyDxM4ypP3Y8knjjKXEOZ23mrNJzJpObnI0KTF2UmMcxLkEu/FhN17E7+WtfTVsqPBy4dypXDx/OkTF0dzp4adr9tLQ7uGOS6ZT2tDO+sIaKhqtbaENMCMzgWUzMlg8LY0YVxQGO36bHcSO3Wbr/X0ZoLSxk61Hmvi4tJF9Va1kJ8Vw9qRkFuUlk58Zh8PhxIeNNg+0evw0dxlau3y0dftp9fiId0WRnRzNxMRooqPsEPhNd3j9NHX48Pr82GwGuxjsAnabHZvDic3uwO6IwuV04LDbj/1ujR/8Puuz8fWfdD/BG2E/NgceY6Oh009Llw+7CHab4LAL9j7/drCe3mDwm2M3aIl3OYl3O7DZgvx5IRTKcL8BWG6M+Wrg8ReAJcaYO/u02RVoUxZ4XBRoM+QMmIa7OlXdXj+3P/kxb+49Omzb+1cu5JqF2cM/qbcLmsqgvd4a4umot3ri3k5a29rZeqiaA5WNzLj8y1x00eUnXbPpauHZ1S/hbCxhYXwLuY56HC2V1nxF8hRImWJ99nZC+ceY8o/xVmzHabqHfM6eeQub6I6Up8Nv5Ljfod8IPmz4EfzYEAwCCH564lww9Dww2PAh+IwNPzartfSeDrSx3tSMEfbkfY7zb/nFKdUbbLgHP5sUAiJyG3AbQF5e3kj+aDWGRDlsPPyFcyisacXnN4iAIHh81pr92tYu6lqtUPxUsBOLDpe1wVnq8ZO7ccCFgY9TJa54bvzs54NrvGAlAjh9HkxHA42dfkobOjnS0EVNq4cubHT57Hj8kJfs5rPzk5DOZuhqhu5jq2WqWzr5oLCWxVNSA/MGAhgwBmP8FFa3sONIHcbvx44fOz7E+PD5/XR7/Xh8fvx+P5NTY5g9IY60WCc9/dnWLi8HjrZSVN2CGB+xTiHWCdEOiHHacDvA7bDhskN7t4/G9m4a2j00tnUhYoh22olx2oh2CjabDWMEH1aoGuMHnxcxXvB58fl9eHx+PF6rLh9gszkQux27zQ5iw28MPr8fv9/g9/v7BOkgr4UY4pxCjBPiHOC2Gwzgs341+I0JhLkfMYEPkcBfBdZHl8/Q5fHR6TV0e33YxRBlMzhtBgcGPwafz+D1W3WJYP1VEviIm7Tw1P9jCpIOyyil1CgSbM89mDVsm4AZIjJFRKKAlcDqAW1WAz2bi9wArD1RsCullDqzhh2WMcZ4ReRO4DWspZCPGWN2i8hPgM3GmNXA/wFPiEghUI/1BqCUUipMghpzN8asAdYMOPajPl93Ap8NbWlKKaVOlW4/oJRSY5CGu1JKjUEa7kopNQZpuCul1Bik4a6UUmNQ2Lb8FZEa4PApfnsacPKbe48srfH0RXp9EPk1Rnp9EPk1Rlp9k4wx6cM1Clu4nw4R2RzMFVrhpDWevkivDyK/xkivDyK/xkivbyg6LKOUUmOQhrtSSo1BozXcHw53AUHQGk9fpNcHkV9jpNcHkV9jpNc3qFE55q6UUurERmvPXSml1AmMunAXkeUisl9ECkXke+GuB0BEHhOR6sAdqXqOpYjIGyJyMPA5OYz15YrI2yKyR0R2i8hdEVijW0Q+EpHtgRr/NXB8iohsDLzefw5sOx02ImIXka0i8nKE1ndIRHaKyDYR2Rw4Fkmvc5KIPCci+0Rkr4icF2H15Qd+dz0fzSLyrUiqMVijKtwDN+t+AFgBzAFWicic8FYFwO+A5QOOfQ94yxgzA3gr8DhcvMC3jTFzgKXAHYHfWyTV2AVcZoxZACwElovIUuA+4NfGmOlAA3BLGGsEuAvY2+dxpNUHcKkxZmGf5XuR9DrfD7xqjJkFLMD6XUZMfcaY/YHf3ULgHKAd+Esk1Rg0Y8yo+QDOA17r8/j7wPfDXVeglsnArj6P9wNZga+zgP3hrrFPbS8BV0ZqjUAM8DGwBOviEcdgr38Y6srB+h/7MuBlrHuuRUx9gRoOAWkDjkXE6wwkAiUE5voirb5B6v0EsD6SazzRx6jquQPZQGmfx2WBY5Eo0xhTGfi6CsgMZzE9RGQysAjYSITVGBjy2AZUA28ARUCjMcYbaBLu1/s3wHcBf+BxKpFVH1g3OX1dRLYE7lkMkfM6TwFqgMcDQ1uPikhsBNU30ErgqcDXkVrjkEZbuI9Kxnq7D/uyJBGJA54HvmWMae57LhJqNMb4jPXncA6wGJgVznr6EpFPA9XGmC3hrmUYy4wxZ2MNXd4hIhf1PRnm19kBnA381hizCGhjwPBGJPx3CBCYO7kaeHbguUipcTijLdzLgdw+j3MCxyLRURHJAgh8rg5nMSLixAr2J40xLwQOR1SNPYwxjcDbWMMcSYGbrkN4X+8LgKtF5BDwNNbQzP1ETn0AGGPKA5+rscaKFxM5r3MZUGaM2Rh4/BxW2EdKfX2tAD42xhwNPI7EGk9otIV7MDfrjhR9bxr+Jaxx7rAQEcG6z+1eY8yv+pyKpBrTRSQp8HU01pzAXqyQvyHQLGw1GmO+b4zJMcZMxvrvbq0x5u8jpT4AEYkVkfier7HGjHcRIa+zMaYKKBWR/MChy4E9REh9A6zi2JAMRGaNJxbuQf9TmOS4CjiANR77g3DXE6jpKaAS8GD1Tm7BGo99CzgIvAmkhLG+ZVh/Ru4AtgU+roqwGucDWwM17gJ+FDg+FfgIKMT6E9kVAa/3JcDLkVZfoJbtgY/dPf9/RNjrvBDYHHidXwSSI6m+QI2xQB2Q2OdYRNUYzIdeoaqUUmPQaBuWUUopFQQNd6WUGoM03JVSagzScFdKqTFIw10ppcYgDXellBqDNNyVUmoM0nBXSqkx6P8DsC5qSrxnYgMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_values)\n",
    "plt.plot(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"part1.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"trained.m\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chenking Train and Test accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(imgs)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = torch.from_numpy(np.asarray([imgs[i]])).float()\n",
    "        labels = torch.from_numpy(np.asarray([lbls[i]])).long()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making your own custom Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
